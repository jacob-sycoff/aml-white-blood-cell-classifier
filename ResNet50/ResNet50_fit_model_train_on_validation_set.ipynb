{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT5LJ9iKqkmT"
   },
   "source": [
    "# ResNet Model Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrP7uZLmeP2N"
   },
   "source": [
    "This notebook shows how to run and train a ResNet50 model. This is how we ran and trained a ResNet50 model and tuned the hyperparameters to receive the best validation accuracy we could. The first part of the notebook shows how to train the model, save checkpoints, and save the full model. The second part shows how to look at the model's precision and recall per cell class. It also shows how to plot a confusion matrix for the validation data. Loading in a checkpoint is shown in the ResNet50_model_load_and_analyze_test_set notebook. There we load in the best checkpoint based on nhighest validation accuracy and test the model on the test set. The final weights we used are included in this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T25HnSnqqsh"
   },
   "source": [
    "## Connect to Data and Download Libaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asAG0IE7Jpbc",
    "outputId": "8ed16931-e706-4195-cd1d-b090717c8b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#Mount GoogleColab to Google Drive. Not a necessary step for those who store the data elsewhere.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWUyL1fAbp9M",
    "outputId": "1b6350ff-899c-45ec-a406-42f86bd68a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n"
     ]
    }
   ],
   "source": [
    "#Needed to plot the confusion matrices later\n",
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtoujD_GqpTk"
   },
   "source": [
    "### Download Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPQXlXwZIL5w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Display\n",
    "#from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwpFYOxvqzCO"
   },
   "source": [
    "### Set Up Paths to Data and Check Number of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYNE_UPSOi0K"
   },
   "outputs": [],
   "source": [
    "#Paths to data\n",
    "train_path = '/content/gdrive/MyDrive/210_data/train'\n",
    "validation_path = '/content/gdrive/MyDrive/210_data/val'\n",
    "test_path = '/content/gdrive/MyDrive/210_data/test'\n",
    "\n",
    "SIZE = 400\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WifcZVzDvYnD",
    "outputId": "8c4474ef-2e3f-490e-b26c-f465ef21e044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18365"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of images in each set \n",
    "num_train_images = sum([len(files) for r, d, files in os.walk(train_path)])\n",
    "num_val_images = sum([len(files) for r, d, files in os.walk(validation_path)])\n",
    "num_test_images = sum([len(files) for r, d, files in os.walk(test_path)])\n",
    "num_train_images + num_val_images + num_test_images #check sum adds to 18,365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqvkBz3DYPFT"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMUSihUMQWta"
   },
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(2,8, figsize = (20,5))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukmDEkVQoHzB"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljyp1SWrJTjQ"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.resnet50.preprocess_input,\n",
    "    rescale = 1./255,\n",
    "    #these are the three methods mentioned in the paper for augmenting the images. Use these in second baseline model.\n",
    "    rotation_range=359, \n",
    "    horizontal_flip= True, \n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ja_zUuozcOj6"
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = tf.keras.applications.resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8Ojsq5SsfoM"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = tf.keras.applications.resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qV2qtjjBqqM9",
    "outputId": "a0e8db5d-ba3f-4c98-88bb-c49cf07a86c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:179: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14687 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory = train_path,  # this is the input directory\n",
    "        target_size=(224, 224),  # all images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUF1vwtRr_Kv",
    "outputId": "9a3d3eab-d729-4994-d88b-0663a74417aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1828 images belonging to 15 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:179: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory = validation_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUvZLpphssAg",
    "outputId": "149bdda5-c4ba-4a14-9df6-05d6d8ad9ada"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:179: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1850 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uH9EWZUd9uo"
   },
   "outputs": [],
   "source": [
    "#Look at batch of train images\n",
    "imgs, labels = next(train_generator)\n",
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNgL6-YUbNEa"
   },
   "outputs": [],
   "source": [
    "#Import ResNet50 model from keras\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True, weights=None, input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OgG8TIneARM"
   },
   "outputs": [],
   "source": [
    "#Look at model structure \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPMtogULoNH_"
   },
   "source": [
    "## Compile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9zaa9Lgv6ft"
   },
   "outputs": [],
   "source": [
    "#implement model.compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(learning_rate = 0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PKOeBf1kEMC"
   },
   "outputs": [],
   "source": [
    "#Add checkpoints \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#filepath='saved_models/models.h5'\n",
    "filepath= '/content/gdrive/MyDrive/saved_models/no_aug_10_epoch_64_batch_size-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5' # File name includes epoch and validation accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BF0lWccYbzjl"
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch = num_train_images//batch_size, #the 2 slashes division return rounded integer\n",
    "                    epochs = 100,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = num_val_images//batch_size, #the 2 slashes division return rounded integer\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QftOwWHMeEPD"
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('/content/gdrive/MyDrive/saved_models/no_aug_10_epoch_64_batch_size') #change path name to reflect model you are running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nb3ePu8Pvcn"
   },
   "source": [
    "## Predictions Using Saved Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yhps1N4m0sgq"
   },
   "outputs": [],
   "source": [
    "#Check out validation images for one batch of val data\n",
    "val_imgs, val_labels = next(validation_generator)\n",
    "plotImages(val_imgs)\n",
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD5jpNUZddFP"
   },
   "outputs": [],
   "source": [
    "#Print the accuracy and loss for validation data\n",
    "loss,acc = model.evaluate(validation_generator, batch_size = 64 , verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jQ_P8D80s76"
   },
   "outputs": [],
   "source": [
    "#all cell types/labels for val set\n",
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQk_QN-mfwxB"
   },
   "outputs": [],
   "source": [
    "#validation predictions\n",
    "val_predictions = model.predict(x = validation_generator, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bq_5f_KucF9K"
   },
   "outputs": [],
   "source": [
    "#gives order of cell types \n",
    "val_dic = validation_generator.class_indices \n",
    "val_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHbhtxYjdzyI"
   },
   "outputs": [],
   "source": [
    "#Cell breakdown of different cell types\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['BAS','EBO','EOS','KSC','LYA','LYT','MMZ','MOB','MON','MYB','MYO','NGB','NGS','PMB','PMO']\n",
    "print(classification_report(validation_generator.classes, np.argmax(val_predictions, axis = -1), target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-dA3QDtd2-K"
   },
   "outputs": [],
   "source": [
    "#invert the val_dic for ease of calling cell names to map for confusion matrix in next cells\n",
    "inv_val_dic = inv_map = {v: k for k, v in val_dic.items()}\n",
    "inv_val_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZvUKGtxHFp0"
   },
   "outputs": [],
   "source": [
    "def map_to_labels(array):\n",
    "    labeled_array = []\n",
    "    for integer in array:\n",
    "        labeled_array.append(inv_val_dic[integer])\n",
    "    return labeled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-fSOq3WczJF"
   },
   "outputs": [],
   "source": [
    "#Plot confusion matrix of different cell types for validation data\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    map_to_labels(validation_generator.classes), \n",
    "    map_to_labels(np.argmax(val_predictions, axis = -1)),\n",
    "    title = \"RestNet50 Validation Confusion Matrix\",\n",
    "    figsize=(12,10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "ResNet50_load_and_fit_model_train_on_validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
